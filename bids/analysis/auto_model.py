from bids.grabbids import BIDSLayout
from bids.analysis.variables import load_event_variables
from collections import OrderedDict
import json
import numpy as np

def make_passthrough_contrast(level,contrast_names):
    block = OrderedDict()
    block["level"] = level
    block["model"] = {"variables": contrast_names}
    contrasts = []
    for cn in contrast_names:
        cdict = OrderedDict()
        cdict["name"] = level+"_"+cn
        cdict["condition_list"] = [cn]
        cdict["weights"] = [1]
        cdict["type"] = "T"
        contrasts.append(cdict)
    block["contrasts"] = contrasts
    return block

def auto_model(layout):
    '''Create a simple default model for each of the tasks in a BIDSLayout.
    Contrasts each trial type against all other trial types and trial types
    at the run level and then uses t-tests at each other level present to 
    aggregate these results up.
    
    Args:
        layout (BIDSLayout) A BIDSLayout instance
    Return:
        models (list) list of model dictionaries for each task
    '''
    
    base_name = op.split(layout.root)[-1]
    tasks = layout.entities['task'].unique()
    task_models = []
    for task_name in tasks:
        # Populate model meta-data
        model = OrderedDict()
        model["name"] = "_".join([base_name, task_name])
        model["description"] = "Autogenerated model for the %s task from %s"%(task_name, base_name)
        model["input"] = {"task": task_name}
        blocks = []

        # Make run level block
        run = OrderedDict()
        run["level"] = "run"
        transformations = OrderedDict()
        transformations["name"] = "factor"
        transformations["input"] = ["trial_type"]
        run["transformations"] = transformations

        # Get trial types
        evs = load_event_variables(layout, task = task_name)
        trial_types = np.unique(evs['trial_type'].values)
        trial_type_factors = ["trial_type." + tt for tt in trial_types]

        run_model = OrderedDict()
        run_model["HRF_variables"] = trial_type_factors
        run_model["variables"] = trial_type_factors
        run["model"] = run_model


        #if there are multiple trial types, build contrasts
        contrasts = []
        for i,tt in enumerate(trial_types):
            cdict = OrderedDict()
            if len(trial_types) > 1:
                cdict["name"] = tt + "_vs_others"
            else:
                cdict["name"] = tt
            cdict["condition_list"] = trial_type_factors

            # Calculate weights for contrast
            weights = np.ones(len(trial_types))
            try:
                weights[trial_types != tt] = -1.0 / (len(trial_types) - 1)
            except ZeroDivisionError:
                pass
            cdict["weights"] = list(weights)

            cdict["type"] = "T"
            contrasts.append(cdict)

        run["contrasts"] = contrasts
        blocks.append(run)

        # if there are multiple sessions, t-test run level contrasts at session level
        sessions = layout.get_sessions()
        if len(sessions) > 1:
            # get contrasts names from previous block
            contrast_names = [cc["name"] for cc in blocks[-1]["contrasts"]]
            blocks.append(make_passthrough_contrast("session", contrast_names))

        subjects = layout.get_subjects()
        if len(subjects) > 1:
            # get contrasts names from previous block
            contrast_names = [cc["name"] for cc in blocks[-1]["contrasts"]]
            blocks.append(make_passthrough_contrast("subject", contrast_names))

        # get contrasts names from previous block
        contrast_names = [cc["name"] for cc in blocks[-1]["contrasts"]]
        blocks.append(make_passthrough_contrast("dataset", contrast_names))

        model["blocks"] = blocks
        task_models.append(model)
    return task_models